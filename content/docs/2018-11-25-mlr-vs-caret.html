---
title: "mlr vs. caret"
authors: ["philipp-probst"]
date: 2018-11-25
categories: ["R", "r-bloggers"]
output:
  blogdown::html_page:
    toc: true
tags: ["mlr", "caret", "machine learning", "R"]
---


<div id="TOC">
<ul>
<li><a href="#installation">Installation</a></li>
<li><a href="#documentation">Documentation</a></li>
<li><a href="#simple-code-example">Simple code example</a></li>
<li><a href="#features">Features</a><ul>
<li><a href="#preprocessing">Preprocessing</a></li>
<li><a href="#tasks">Tasks</a></li>
<li><a href="#learners">Learners</a></li>
<li><a href="#resampling-strategies">Resampling strategies</a></li>
<li><a href="#measures">Measures</a></li>
<li><a href="#benchmarking">Benchmarking</a></li>
<li><a href="#tuning">Tuning</a></li>
<li><a href="#visualization-of-results">Visualization of results</a></li>
<li><a href="#datasets">Datasets</a></li>
</ul></li>
<li><a href="#speed">Speed</a><ul>
<li><a href="#difference-in-the-default-mode">Difference in the default mode</a></li>
<li><a href="#parallelization">Parallelization</a></li>
</ul></li>
<li><a href="#objects-and-configurability">Objects and configurability</a></li>
<li><a href="#further-development">Further development</a></li>
<li><a href="#overall-result">Overall result</a><ul>
<li><a href="#overview-in-table">Overview in table</a></li>
<li><a href="#thanks">Thanks</a></li>
</ul></li>
</ul>
</div>

<p>Let`s compare the two popular R packages for machine learning <a href="https://github.com/mlr-org/mlr">mlr</a> and <a href="https://github.com/topepo/caret">caret</a>.</p>
<p>caret is longer on the market, its first CRAN release seems to be from 2007, while mlr came to CRAN on 2013. As for now, caret seems to be more popular, according to <a href="https://cran.r-project.org/web/packages/cranlogs/index.html">cranlogs</a> caret was downloaded 178029 times in the last 30 days, while mlr was downloaded 11408 times in the last 28 days.</p>
<!--excerpt-->
<p>The purpose of the packages seems to be quite similar. The caret website defines caret as follows:</p>
<blockquote>
<p><em>The caret package (short for Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models.</em></p>
</blockquote>
<p>The purpose of mlr is described on their website:</p>
<blockquote>
<p><em>R does not define a standardized interface for all its machine learning algorithms. Therefore, for any non-trivial experiments, you need to write lengthy, tedious and error-prone wrappers to call the different algorithms and unify their respective output. [. . .] The framework provides supervised methods like classification, regression and survival analysis along with their corresponding evaluation and optimization methods, as well as unsupervised methods like clustering. It is written in a way that you can extend it yourself or deviate from the implemented convenience methods and construct your own complex experiments or algorithms.</em></p>
</blockquote>
<p>Both packages want to automatize standard processes for standard tasks like classification and regression and make life easier for data scientists. So which package to use? I will try to do a fair comparison of these two packages. As I contributed to the mlr package I may be biased, but I will try to do it as fair as possible.</p>
<div id="installation" class="section level1">
<h1>Installation</h1>
<p>Both packages heavily depend on other packages and hence installation takes a long time. I tested both packages on my windows machine with a fresh R version and without having installed any dependencies beforehand. For caret it took me 140 seconds while for mlr it took 46 seconds without including suggested packages.</p>
</div>
<div id="documentation" class="section level1">
<h1>Documentation</h1>
<p>Both have an online tutorial. <a href="http://topepo.github.io/caret/index.html">caret`s one</a> is good for learning from scratch, but for looking things up quickly it is rather unpractical. Here lies the strength of the <a href="https://mlr.mlr-org.com/index.html">mlr tutorial</a>.</p>
<p>caret provides more things. There is the <a href="https://www.springer.com/de/book/9781461468486">Applied Predictive Modelling book</a> which tries to <em>cover the overall predictive modeling process.</em> It is not freely available online, like ,for example, some books of Hadley Wickham (e.g., <a href="http://adv-r.had.co.nz/">Advanced R</a>, <a href="https://r4ds.had.co.nz/">R for Data Science</a> or <a href="http://r-pkgs.had.co.nz/">R packages</a>) or <a href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf">The elements of statistical learning</a>.</p>
<p>Moreover there is a <a href="https://www.datacamp.com/courses/machine-learning-toolbox">datacamp course</a> that uses caret.</p>
<p>Cheatsheets are available for both. The one for <a href="https://github.com/rstudio/cheatsheets/raw/master/mlr.pdf">mlr</a> seems to be more extensive and detailed than the <a href="https://github.com/rstudio/cheatsheets/raw/master/caret.pdf">caret</a> one.</p>
<p>All in all, especially because of the nice book, caret seems to be the winner here.</p>
</div>
<div id="simple-code-example" class="section level1">
<h1>Simple code example</h1>
<p>To compare the two packages directly here you can see the standard codes of lines that are necessary to perform a simple 5-fold cross-validation for the boston housing dataset and random forest package ranger.</p>
<p>For mlr:</p>
<pre class="r"><code>library(mlr)
data(BostonHousing, package = &quot;mlbench&quot;)
regr.task = makeRegrTask(data = BostonHousing, target = &quot;medv&quot;)
lrn = makeLearner(&quot;regr.ranger&quot;)
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 5)
res = resample(learner = lrn, task = regr.task, resampling = rdesc, measure = list(RMSE))
res</code></pre>
<p>For caret:</p>
<pre class="r"><code>library(caret)
data(BostonHousing, package = &quot;mlbench&quot;)
fitControl = trainControl(method = &quot;cv&quot;, number = 5)
fit = train(medv ~ ., data = BostonHousing, method = &quot;ranger&quot;, trControl = fitControl)
fit</code></pre>
<p>In this code you can already see a crucial difference. In mlr you have to create a task and a learner. This means more code writing, but gives the user also more flexibility and overview of what he is doing. In caret you can give the data and the method directly to the <code>train</code> function and internally some tuning is done for the user without having the possibility to adjust this easily.</p>
<p>Things can be changed in both packages (e.g., by giving directly the character <code>&quot;regr.ranger&quot;</code> as learner in <code>train</code> or by creating your own learner in caret like described <a href="http://topepo.github.io/caret/using-your-own-model-in-train.html">here</a>) but these are the standard ways of doing things in the two packages.</p>
<p>No clear winner here.</p>
</div>
<div id="features" class="section level1">
<h1>Features</h1>
<p>Let`s compare the different feature that the two packages have to offer for different issues of the machine learning process.</p>
<div id="preprocessing" class="section level2">
<h2>Preprocessing</h2>
<p>Both packages have several possibilities for preprocessing of the dataset. Both include standard procedures like dummy feature creation (e.g. for categorical predictors), normalization and imputation and include several feature selection methods. In caret also standard transformations (scaling, PCA, Box-Cox, Yeo-Johnson, etc.) can be used. An advantage of mlr is, that all preprocessing methods of caret can be used via a Wrapper that makes them accessible for mlr. In both packages these preprocessing steps can be used in the resampling process.</p>
<p>No clear winner here.</p>
</div>
<div id="tasks" class="section level2">
<h2>Tasks</h2>
<p>mlr has more possibilities to create different tasks: Classification, Regression, Survival, Clustering, Multilabel, Cost-sensitive, Imbalanced data, Functional data, Spatial data.</p>
<p>caret only seems to have possibilities for Classification, Regression and Cost-sensitive.</p>
<p>mlr is better here.</p>
</div>
<div id="learners" class="section level2">
<h2>Learners</h2>
<p>Currently 271 learners are supported in caret. For mlr it is <em>only</em> 165. I think bigger quantity is not very important here, as the most common and most important learners are implemented in both packages.</p>
<p>mlr provides an easy way to look up the learners and their properties via <code>listLearners()</code> or via the <a href="(https://mlr.mlr-org.com/index.html)">tutorial</a> in a table format. Learners for caret can be looked up in the tutorial, <a href="http://topepo.github.io/caret/train-models-by-tag.html">chapter 7</a>. Both packages provide the possibility to extend the learners.</p>
<p>What is clearly missing is a list of recommended learners in both packages. New users just have to look for the <em>standard</em> packages, without knowing if they are good or if there are possibly better implementations.</p>
<p>No clear winner here, although documentation seems to be better for mlr here.</p>
</div>
<div id="resampling-strategies" class="section level2">
<h2>Resampling strategies</h2>
<p>There are several resampling strategies available in both packages. Of course both include the most standard procedure (repeated) k-fold cross-validation. Moreover the strategies holdout, bootstrap and leave-one-out are available for both. Both have the option for growing window cross-validation which is especially useful for time series data. caret has additionally the possibility to use out-of-bag methods that are available for methods that use bagging like e.g. random forest. This is not available for mlr, only the out-of-bag predictions of a normally trained random forest model can be extracted here.</p>
<p>Small advantage for caret.</p>
</div>
<div id="measures" class="section level2">
<h2>Measures</h2>
<p>In mlr there are currently <a href="https://mlr.mlr-org.com/articles/tutorial/measures.html">71 measures</a> implemented for all the different tasks that can be handled in mlr. Custom measures can be added by the user (see <a href="https://mlr.mlr-org.com/articles/tutorial/create_measure.html">here</a>). Only one measure is given as default (mse in regression and mmce in classification).</p>
<p>caret has two standard measures that are used for each of the tasks (RMSE and Rsquared for regression and Accuracy and Kappa for classification). They are changeable via the <code>trainControl</code> argument but it is more complicated to do that than in mlr, I would say.</p>
<p>mlr wins here.</p>
</div>
<div id="benchmarking" class="section level2">
<h2>Benchmarking</h2>
<p>mlr provides a function for executing a benchmark of several learners and several datasets/tasks at once (also parallelizable). No such functionality is available in caret.</p>
</div>
<div id="tuning" class="section level2">
<h2>Tuning</h2>
<p>Tuning is done internally and automatically in the caret package. What is tuned is described in the <a href="http://topepo.github.io/caret/train-models-by-tag.html">learner section</a> of the tutorial. This can be changed by the user to grid search or random search.</p>
<p>In mlr tuning is not done automatically. There are functions and wrappers to perform the tuning. Tuning methods that are supported are random search, grid search, F-Racing and model-based optimization via the mlrMBO package.</p>
<p>For both packages there are plots to visualize the tuning process.</p>
<p>Light advantage for mlr here as it support advanced tuning algorithms like F-Racing and model-based optimization.</p>
</div>
<div id="visualization-of-results" class="section level2">
<h2>Visualization of results</h2>
<p>Visualising your results and getting informations about your models is an important task in the modelling pipeline. Both packages provide a lot of possibilities here. For both packages we have ROC-Analysis and calibration curves. For mlr there are additionally partial dependence plots, learning curves, cut-off curves and residual plotting, while caret provides method specific variable importances and lift curves.</p>
<p>No clear winner here.</p>
</div>
<div id="datasets" class="section level2">
<h2>Datasets</h2>
<p>Datasets can be nice for illustration and testing purposes. caret comes with 10 datasets, which are nicely <a href="http://topepo.github.io/caret/data-sets.html">documented</a>. mlr provides 16 already build tasks. Moreover there is a nice connection to the <a href="https://github.com/openml/openml-r">OpenML</a> package and its <a href="https://www.openml.org/">online platform</a> with over 20000 datasets from all domains.</p>
<p>Advantage for mlr here.</p>
</div>
</div>
<div id="speed" class="section level1">
<h1>Speed</h1>
<p>There shouldn`t be a big time difference for the operations of the package itself as most of the operations are not computationally intensive.</p>
<div id="difference-in-the-default-mode" class="section level2">
<h2>Difference in the default mode</h2>
<p>caret has prespecified tuning if the learners are used in their default version so it will in the default mode take more time than mlr for which tuning is not done in the default method. In the example above it lead to a runtime of 2.4 seconds for mlr and 3.2 seconds for caret. In general the automatic tuning will also lead to better performance.</p>
<p>No clear winner here.</p>
</div>
<div id="parallelization" class="section level2">
<h2>Parallelization</h2>
<p>Parallelization in the caret package only works internally when applying a tuning strategy like grid search by using the <a href="http://topepo.github.io/caret/parallel-processing.html">doParallel</a> package which is based on <a href="https://cran.r-project.org/web/packages/snow/index.html">snow</a>.</p>
<p>In contrast in mlr you have more options. You can parallelize on different <a href="https://mlr.mlr-org.com/articles/tutorial/parallelization.html">levels</a>: While using benchmark with different learners and datasets, when resampling, while selecting Features, while tuning and while training an ensemble. Parallelization can be done via <a href="https://cran.r-project.org/web/packages/parallelMap/index.html">parallelMap</a> which works with all major parallelization backends: <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf">parallel</a>, <a href="https://cran.r-project.org/web/packages/snow/index.html">snow</a> or via <a href="https://cran.r-project.org/web/packages/batchtools/batchtools.pdf">batchtools</a>. Especially useful is the function <code>batchmark</code> which is good for parallelizing benchmarks via <a href="https://cran.r-project.org/web/packages/batchtools/batchtools.pdf">batchtools</a>.</p>
<p>mlr has more possibilities here.</p>
</div>
</div>
<div id="objects-and-configurability" class="section level1">
<h1>Objects and configurability</h1>
<p>In mlr you have an object for every part of the process: a task, a learner, a measure, a resample object. In caret you have the <code>trainControl</code> object which is configurable, but I would say that mlr is more intuitive and clear here. Because of this it is also easier in mlr to integrate new custom learners, measures, filters and imputation methods.</p>
<p>mlr wins here.</p>
</div>
<div id="further-development" class="section level1">
<h1>Further development</h1>
<p>Caret will be retired. New developments include the packages recipes, yardstick, infer, parsnip and are all part of tidymodels.</p>
<p>mlr developers are currently working on <a href="https://github.com/mlr-org/mlr3">mlr3</a> which aims at being even more extensible and using R6, data.table and other useful packages that were not used by mlr.</p>
</div>
<div id="overall-result" class="section level1">
<h1>Overall result</h1>
<p>Counting together all categories mlr wins by 13:7.</p>
<div id="overview-in-table" class="section level2">
<h2>Overview in table</h2>
</div>
<div id="thanks" class="section level2">
<h2>Thanks</h2>
<p>Thanks to Rahul Sangole, who helped me a bit with informations about the caret package as I was not very familiar with it.</p>
</div>
</div>
